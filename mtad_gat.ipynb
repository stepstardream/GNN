{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96e7b3c4847048b3886e97eb0c3529af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48b29049446e4838b731ec1c6f74ed0a",
              "IPY_MODEL_f3fd28b2daf0498098e9b1e09f2f1875",
              "IPY_MODEL_ea9faea6b7274c30a733e2e57b19319f"
            ],
            "layout": "IPY_MODEL_a525147ac1b04af8be036b41a2d5f2cc"
          }
        },
        "48b29049446e4838b731ec1c6f74ed0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0a03ccf9fcc4d7fa40eea0f20c22289",
            "placeholder": "​",
            "style": "IPY_MODEL_e66f4d780b064b57942a4c7bd70e0840",
            "value": "100%"
          }
        },
        "f3fd28b2daf0498098e9b1e09f2f1875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dcbdfe3ce27437fa22578957b12d1a4",
            "max": 39,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ea3c5665fb34374b71c60836a1f3763",
            "value": 39
          }
        },
        "ea9faea6b7274c30a733e2e57b19319f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfba0ae200d149258e39ea392c3288dc",
            "placeholder": "​",
            "style": "IPY_MODEL_f1bb6cb8a28842c69b104d01f99e9e6b",
            "value": " 39/39 [00:11&lt;00:00,  3.80it/s]"
          }
        },
        "a525147ac1b04af8be036b41a2d5f2cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0a03ccf9fcc4d7fa40eea0f20c22289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e66f4d780b064b57942a4c7bd70e0840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dcbdfe3ce27437fa22578957b12d1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ea3c5665fb34374b71c60836a1f3763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfba0ae200d149258e39ea392c3288dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1bb6cb8a28842c69b104d01f99e9e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stepstardream/graph-neural-network/blob/main/mtad_gat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3-us-west-2.amazonaws.com/telemanom/data.zip"
      ],
      "metadata": {
        "id": "L29vJy96EcN0",
        "outputId": "5e30d862-ac70-4cd7-8ca0-f6901fc23ad4",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:07:58.774104Z",
          "iopub.execute_input": "2023-04-09T03:07:58.774841Z",
          "iopub.status.idle": "2023-04-09T03:08:01.012426Z",
          "shell.execute_reply.started": "2023-04-09T03:07:58.774807Z",
          "shell.execute_reply": "2023-04-09T03:08:01.011082Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-09 04:49:14--  https://s3-us-west-2.amazonaws.com/telemanom/data.zip\n",
            "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.219.56, 52.92.241.136, 52.92.213.136, ...\n",
            "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.219.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85899803 (82M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  81.92M  35.6MB/s    in 2.3s    \n",
            "\n",
            "2023-04-09 04:49:17 (35.6 MB/s) - ‘data.zip’ saved [85899803/85899803]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq data.zip"
      ],
      "metadata": {
        "id": "9VtmxSzdEs2i",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:08:06.543730Z",
          "iopub.execute_input": "2023-04-09T03:08:06.544510Z",
          "iopub.status.idle": "2023-04-09T03:08:09.374819Z",
          "shell.execute_reply.started": "2023-04-09T03:08:06.544466Z",
          "shell.execute_reply": "2023-04-09T03:08:09.373259Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ML4ITS/mtad-gat-pytorch.git"
      ],
      "metadata": {
        "id": "XfkGAoKdEy2B",
        "outputId": "5c39e89e-4eda-4648-fe1b-1a57a90c90a3",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:06:29.937016Z",
          "iopub.execute_input": "2023-04-09T03:06:29.937446Z",
          "iopub.status.idle": "2023-04-09T03:07:23.957362Z",
          "shell.execute_reply.started": "2023-04-09T03:06:29.937404Z",
          "shell.execute_reply": "2023-04-09T03:07:23.956104Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mtad-gat-pytorch'...\n",
            "remote: Enumerating objects: 6170, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 6170 (delta 3), reused 2 (delta 0), pack-reused 6161\u001b[K\n",
            "Receiving objects: 100% (6170/6170), 920.66 MiB | 34.66 MiB/s, done.\n",
            "Resolving deltas: 100% (2700/2700), done.\n",
            "Updating files: 100% (158/158), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "aGkrIpBEE5xZ",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:07:31.010997Z",
          "iopub.execute_input": "2023-04-09T03:07:31.011691Z",
          "iopub.status.idle": "2023-04-09T03:07:33.553317Z",
          "shell.execute_reply.started": "2023-04-09T03:07:31.011653Z",
          "shell.execute_reply": "2023-04-09T03:07:33.552258Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smap_channels = pd.read_csv('mtad-gat-pytorch/datasets/data/smap_train_md.csv')\n",
        "print(\"Number of Channels : \", len(smap_channels))\n",
        "smap_channels.head(5)\n",
        "smap_channels = list(smap_channels['chan_id'].values)\n",
        "len(smap_channels)"
      ],
      "metadata": {
        "id": "kMwAie0kE9V_",
        "outputId": "65773d60-acb3-44e8-fe08-0d7c58ef7151",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:07:34.021260Z",
          "iopub.execute_input": "2023-04-09T03:07:34.022572Z",
          "iopub.status.idle": "2023-04-09T03:07:34.045332Z",
          "shell.execute_reply.started": "2023-04-09T03:07:34.022523Z",
          "shell.execute_reply": "2023-04-09T03:07:34.044071Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Channels :  53\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smap_data = []\n",
        "for smap_channel in smap_channels:\n",
        "    tmp_data = np.load(os.path.join('data/train/', smap_channel + '.npy'))\n",
        "    smap_data.extend(tmp_data)\n",
        "    \n",
        "smap_data = np.array(smap_data)\n",
        "print(\"Shape of SMAP Data : \", smap_data.shape)"
      ],
      "metadata": {
        "id": "OxR-WSdAFGV2",
        "outputId": "c3164d36-9005-49a9-c2f6-a977cb347980",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:08:16.013035Z",
          "iopub.execute_input": "2023-04-09T03:08:16.013828Z",
          "iopub.status.idle": "2023-04-09T03:08:16.138891Z",
          "shell.execute_reply.started": "2023-04-09T03:08:16.013784Z",
          "shell.execute_reply": "2023-04-09T03:08:16.137909Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of SMAP Data :  (135183, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
        "def normalize_data(data, scaler=None):\n",
        "    data = np.asarray(data, dtype=np.float32)\n",
        "    if np.any(sum(np.isnan(data))):\n",
        "        data = np.nan_to_num(data)\n",
        "\n",
        "    if scaler is None:\n",
        "        scaler = MinMaxScaler()\n",
        "        scaler.fit(data)\n",
        "    data = scaler.transform(data)\n",
        "    print(\"Data normalized\")\n",
        "\n",
        "    return data, scaler"
      ],
      "metadata": {
        "id": "HJe4WvA5FKiF",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:08:20.629800Z",
          "iopub.execute_input": "2023-04-09T03:08:20.630347Z",
          "iopub.status.idle": "2023-04-09T03:08:20.643391Z",
          "shell.execute_reply.started": "2023-04-09T03:08:20.630300Z",
          "shell.execute_reply": "2023-04-09T03:08:20.642334Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smap_data_norm, scaler = normalize_data(smap_data)\n",
        "smap_data_pt = torch.from_numpy(smap_data)\n",
        "smap_data_pt.size()"
      ],
      "metadata": {
        "id": "XYvBoiu_FPS_",
        "outputId": "d8fa50f5-90da-4db1-9637-fc7ff25d381e",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:08:22.667053Z",
          "iopub.execute_input": "2023-04-09T03:08:22.667762Z",
          "iopub.status.idle": "2023-04-09T03:08:22.869119Z",
          "shell.execute_reply.started": "2023-04-09T03:08:22.667725Z",
          "shell.execute_reply": "2023-04-09T03:08:22.868175Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data normalized\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([135183, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SlidingWindowDataset(Dataset):\n",
        "    def __init__(self, data, window, target_dim=None, horizon=1):\n",
        "        self.data = data\n",
        "        self.window = window\n",
        "        self.target_dim = target_dim\n",
        "        self.horizon = horizon\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index : index + self.window]\n",
        "        y = self.data[index + self.window : index + self.window + self.horizon]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.window"
      ],
      "metadata": {
        "id": "-L3a6DZiFS7h",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:08:27.041602Z",
          "iopub.execute_input": "2023-04-09T03:08:27.041983Z",
          "iopub.status.idle": "2023-04-09T03:08:27.050288Z",
          "shell.execute_reply.started": "2023-04-09T03:08:27.041949Z",
          "shell.execute_reply": "2023-04-09T03:08:27.048890Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Window = 100\n",
        "BatchSZ =  256\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "dRvPpy1vFV28",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:08:29.677035Z",
          "iopub.execute_input": "2023-04-09T03:08:29.677451Z",
          "iopub.status.idle": "2023-04-09T03:08:29.747833Z",
          "shell.execute_reply.started": "2023-04-09T03:08:29.677417Z",
          "shell.execute_reply": "2023-04-09T03:08:29.746648Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smap_x_y = SlidingWindowDataset(smap_data_pt, 100)"
      ],
      "metadata": {
        "id": "5B7ur4FdFZDM",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:08:32.464754Z",
          "iopub.execute_input": "2023-04-09T03:08:32.465123Z",
          "iopub.status.idle": "2023-04-09T03:08:32.469959Z",
          "shell.execute_reply.started": "2023-04-09T03:08:32.465089Z",
          "shell.execute_reply": "2023-04-09T03:08:32.468920Z"
        },
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loaders(train_dataset, batch_size, val_split=0.1, shuffle=True, test_dataset=None):\n",
        "    train_loader, val_loader, test_loader = None, None, None\n",
        "    if val_split == 0.0:\n",
        "        print(f\"train_size: {len(train_dataset)}\")\n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    else:\n",
        "        dataset_size = len(train_dataset)\n",
        "        indices = list(range(dataset_size))\n",
        "        split = int(np.floor(val_split * dataset_size))\n",
        "        if shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "        train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "        train_sampler = SubsetRandomSampler(train_indices)\n",
        "        valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "        val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "        print(f\"train_size: {len(train_indices)}\")\n",
        "        print(f\"validation_size: {len(val_indices)}\")\n",
        "\n",
        "    if test_dataset is not None:\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "        print(f\"test_size: {len(test_dataset)}\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "hmne9YN0FciN",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:08:33.783183Z",
          "iopub.execute_input": "2023-04-09T03:08:33.783552Z",
          "iopub.status.idle": "2023-04-09T03:08:33.793627Z",
          "shell.execute_reply.started": "2023-04-09T03:08:33.783521Z",
          "shell.execute_reply": "2023-04-09T03:08:33.792419Z"
        },
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl, val_dl, _ = create_data_loaders(smap_x_y, BatchSZ)"
      ],
      "metadata": {
        "id": "UkiCmSPUFfRM",
        "outputId": "73afbe8e-43cb-41be-d547-ea072b054326",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:08:37.034215Z",
          "iopub.execute_input": "2023-04-09T03:08:37.034979Z",
          "iopub.status.idle": "2023-04-09T03:08:37.060505Z",
          "shell.execute_reply.started": "2023-04-09T03:08:37.034939Z",
          "shell.execute_reply": "2023-04-09T03:08:37.059065Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_size: 121575\n",
            "validation_size: 13508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eg = next(iter(val_dl))\n",
        "eg[0].size(), eg[1].size()"
      ],
      "metadata": {
        "id": "AheOZu1UFhY0",
        "outputId": "493c945d-fae3-4ed3-9393-2dc7206c394f",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:08:39.233494Z",
          "iopub.execute_input": "2023-04-09T03:08:39.234037Z",
          "iopub.status.idle": "2023-04-09T03:08:39.315072Z",
          "shell.execute_reply.started": "2023-04-09T03:08:39.233995Z",
          "shell.execute_reply": "2023-04-09T03:08:39.313873Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 100, 25]), torch.Size([256, 1, 25]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# sys.path.insert(0, 'mtad-gat-pytorch/')"
      ],
      "metadata": {
        "id": "Lv99qXotFkmD",
        "execution": {
          "iopub.status.busy": "2023-04-07T09:14:42.175731Z",
          "iopub.execute_input": "2023-04-07T09:14:42.176678Z",
          "iopub.status.idle": "2023-04-07T09:14:42.183710Z",
          "shell.execute_reply.started": "2023-04-07T09:14:42.176642Z",
          "shell.execute_reply": "2023-04-07T09:14:42.182489Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class ConvLayer(nn.Module):\n",
        "    \"\"\"1-D Convolution layer to extract high-level features of each time-series input\n",
        "    :param n_features: Number of input features/nodes\n",
        "    :param window_size: length of the input sequence\n",
        "    :param kernel_size: size of kernel to use in the convolution operation\n",
        "    \"\"\"\n",
        "    def __init__(self, n_features, kernel_size=7):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        self.padding = nn.ConstantPad1d((kernel_size - 1) // 2, 0.0)\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels=n_features, out_channels=n_features, kernel_size=kernel_size\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.padding(x)\n",
        "        x = self.relu(self.conv(x))\n",
        "        return x.permute(0, 2, 1)  # Permute back\n",
        "\n",
        "\n",
        "\n",
        "class FeatureAttentionLayer0(nn.Module):\n",
        "    \"\"\"Single Graph Feature/Spatial Attention Layer\n",
        "    :param n_features: Number of input features/nodes\n",
        "    :param window_size: length of the input sequence\n",
        "    :param dropout: percentage of nodes to dropout\n",
        "    :param alpha: negative slope used in the leaky rely activation function\n",
        "    :param embed_dim: embedding dimension (output dimension of linear transformation)\n",
        "    :param use_gatv2: whether to use the modified attention mechanism of GATv2 instead of standard GAT\n",
        "    :param use_bias: whether to include a bias term in the attention layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_features,\n",
        "        window_size,\n",
        "        dropout,\n",
        "        alpha,\n",
        "        embed_dim=None,\n",
        "        use_gatv2=True,\n",
        "        use_bias=True,\n",
        "    ):\n",
        "        super(FeatureAttentionLayer0, self).__init__()\n",
        "        self.n_features = n_features\n",
        "        self.window_size = window_size\n",
        "        self.dropout = dropout\n",
        "        self.embed_dim = embed_dim if embed_dim is not None else window_size\n",
        "        self.use_gatv2 = use_gatv2\n",
        "        self.num_nodes = n_features\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "        # Because linear transformation is done after concatenation in GATv2\n",
        "        if self.use_gatv2:\n",
        "            self.embed_dim *= 2\n",
        "            lin_input_dim = 2 * window_size\n",
        "            a_input_dim = self.embed_dim\n",
        "        else:\n",
        "            lin_input_dim = window_size\n",
        "            a_input_dim = 2 * self.embed_dim\n",
        "\n",
        "        self.lin = nn.Linear(lin_input_dim, self.embed_dim)\n",
        "        self.a = nn.Parameter(torch.zeros((a_input_dim, 1)))\n",
        "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(n_features, n_features))\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape (b, n, k): b - batch size, n - window size, k - number of features\n",
        "        # C\n",
        "\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # 'Dynamic' GAT attention\n",
        "        # Proposed by Brody et. al., 2021 (https://arxiv.org/pdf/2105.14491.pdf)\n",
        "        # Linear transformation applied after concatenation and attention layer applied after leakyrelu\n",
        "        if self.use_gatv2:\n",
        "            a_input = self._make_attention_input(x)  # (b, k, k, 2*window_size)\n",
        "            a_input = self.leakyrelu(self.lin(a_input))  # (b, k, k, embed_dim)\n",
        "            e = torch.matmul(a_input, self.a).squeeze(3)  # (b, k, k, 1)\n",
        "            \n",
        "\n",
        "        # Original GAT attention\n",
        "        else:\n",
        "            Wx = self.lin(x)  # (b, k, k, embed_dim)\n",
        "            a_input = self._make_attention_input(Wx)  # (b, k, k, 2*embed_dim)\n",
        "            e = self.leakyrelu(torch.matmul(a_input, self.a)).squeeze(3)  # (b, k, k, 1)\n",
        "            \n",
        "\n",
        "        if self.use_bias:\n",
        "            e += self.bias\n",
        "\n",
        "        # Attention weights    \n",
        "        attention = torch.softmax(e, dim=2)\n",
        "        attention = torch.dropout(attention, self.dropout, train=self.training)\n",
        "        # attention = \n",
        "        # Computing new node features using the attention\n",
        "        h = self.sigmoid(torch.matmul(attention, x))\n",
        "        return h.permute(0, 2, 1)\n",
        "\n",
        "    def _make_attention_input(self, v):\n",
        "        \"\"\"Preparing the feature attention mechanism.\n",
        "        Creating matrix with all possible combinations of concatenations of node.\n",
        "        Each node consists of all values of that node within the window\n",
        "            v1 || v1,\n",
        "            ...\n",
        "            v1 || vK,\n",
        "            v2 || v1,\n",
        "            ...\n",
        "            v2 || vK,\n",
        "            ...\n",
        "            ...\n",
        "            vK || v1,\n",
        "            ...\n",
        "            vK || vK,\n",
        "        \"\"\"\n",
        "\n",
        "        # K = self.num_nodes\n",
        "        # blocks_repeating = v.repeat_interleave(K, dim=1)  # Left-side of the matrix    每个元素的重复次数。repeats参数会被广播来适应输入张量的维度\n",
        "        # blocks_alternating = v.repeat(1, K, 1)  # Right-side of the matrix             沿着特定的维度重复这个张量，和expand()不同的是，这个函数拷贝张量的数据\n",
        "        # combined = torch.cat(\n",
        "        #     (blocks_repeating, blocks_alternating), dim=2\n",
        "        # )  # (b, K*K, 2*window_size)\n",
        "        K = self.num_nodes\n",
        "        blocks_repeating = v.repeat_interleave(K, dim=1)  # Left-side of the matrix    每个元素的重复次数。repeats参数会被广播来适应输入张量的维度\n",
        "        blocks_alternating = v.repeat(1, K, 1)  # Right-side of the matrix             沿着特定的维度重复这个张量，和expand()不同的是，这个函数拷贝张量的数据\n",
        "        combined = torch.cat(\n",
        "            (blocks_repeating, blocks_alternating), dim=2\n",
        "        )  # (b, K*K, 2*window_size)\n",
        "\n",
        "        if self.use_gatv2:\n",
        "            return combined.view(v.size(0), K, K, 2 * self.window_size)\n",
        "        else:\n",
        "            return combined.view(v.size(0), K, K, 2 * self.embed_dim)\n",
        "class FeatureAttentionLayer1(nn.Module):\n",
        "    \"\"\"Single Graph Feature/Spatial Attention Layer\n",
        "    :param n_features: Number of input features/nodes\n",
        "    :param window_size: length of the input sequence\n",
        "    :param dropout: percentage of nodes to dropout\n",
        "    :param alpha: negative slope used in the leaky rely activation function\n",
        "    :param embed_dim: embedding dimension (output dimension of linear transformation)\n",
        "    :param use_gatv2: whether to use the modified attention mechanism of GATv2 instead of standard GAT\n",
        "    :param use_bias: whether to include a bias term in the attention layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_features,\n",
        "        window_size,\n",
        "        dropout,\n",
        "        alpha,\n",
        "        embed_dim=None,\n",
        "        use_gatv2=True,\n",
        "        use_bias=True,\n",
        "    ):\n",
        "        super(FeatureAttentionLayer1, self).__init__()\n",
        "        self.n_features = n_features\n",
        "        self.window_size = window_size\n",
        "        self.dropout = dropout\n",
        "        self.embed_dim = embed_dim if embed_dim is not None else window_size\n",
        "        self.use_gatv2 = use_gatv2\n",
        "        self.num_nodes = n_features\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "        # Because linear transformation is done after concatenation in GATv2\n",
        "        if self.use_gatv2:\n",
        "            self.embed_dim *= 2\n",
        "            lin_input_dim = 2 * window_size\n",
        "            a_input_dim = self.embed_dim\n",
        "        else:\n",
        "            lin_input_dim = window_size\n",
        "            a_input_dim = 2 * self.embed_dim\n",
        "\n",
        "        self.lin = nn.Linear(lin_input_dim, self.embed_dim)\n",
        "        self.a = nn.Parameter(torch.rand((a_input_dim, 1)))\n",
        "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = nn.Parameter(torch.rand(n_features, n_features))\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape (b, n, k): b - batch size, n - window size, k - number of features\n",
        "        # C\n",
        "\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # 'Dynamic' GAT attention\n",
        "        # Proposed by Brody et. al., 2021 (https://arxiv.org/pdf/2105.14491.pdf)\n",
        "        # Linear transformation applied after concatenation and attention layer applied after leakyrelu\n",
        "        if self.use_gatv2:\n",
        "            a_input = self._make_attention_input(x)  # (b, k, k, 2*window_size)\n",
        "            a_input = self.leakyrelu(self.lin(a_input))  # (b, k, k, embed_dim)\n",
        "            e = torch.matmul(a_input, self.a).squeeze(3)  # (b, k, k, 1)\n",
        "            \n",
        "\n",
        "        # Original GAT attention\n",
        "        else:\n",
        "            Wx = self.lin(x)  # (b, k, k, embed_dim)\n",
        "            a_input = self._make_attention_input(Wx)  # (b, k, k, 2*embed_dim)\n",
        "            e = self.leakyrelu(torch.matmul(a_input, self.a)).squeeze(3)  # (b, k, k, 1)\n",
        "            \n",
        "\n",
        "        if self.use_bias:\n",
        "            e += self.bias\n",
        "\n",
        "        # Attention weights    \n",
        "        attention = torch.softmax(e, dim=2)\n",
        "        attention = torch.dropout(attention, self.dropout, train=self.training)\n",
        "        # attention = \n",
        "        # Computing new node features using the attention\n",
        "        h = self.sigmoid(torch.matmul(attention, x))\n",
        "        return h.permute(0, 2, 1)\n",
        "\n",
        "    def _make_attention_input(self, v):\n",
        "        \"\"\"Preparing the feature attention mechanism.\n",
        "        Creating matrix with all possible combinations of concatenations of node.\n",
        "        Each node consists of all values of that node within the window\n",
        "            v1 || v1,\n",
        "            ...\n",
        "            v1 || vK,\n",
        "            v2 || v1,\n",
        "            ...\n",
        "            v2 || vK,\n",
        "            ...\n",
        "            ...\n",
        "            vK || v1,\n",
        "            ...\n",
        "            vK || vK,\n",
        "        \"\"\"\n",
        "\n",
        "        # K = self.num_nodes\n",
        "        # blocks_repeating = v.repeat_interleave(K, dim=1)  # Left-side of the matrix    每个元素的重复次数。repeats参数会被广播来适应输入张量的维度\n",
        "        # blocks_alternating = v.repeat(1, K, 1)  # Right-side of the matrix             沿着特定的维度重复这个张量，和expand()不同的是，这个函数拷贝张量的数据\n",
        "        # combined = torch.cat(\n",
        "        #     (blocks_repeating, blocks_alternating), dim=2\n",
        "        # )  # (b, K*K, 2*window_size)\n",
        "        K = self.num_nodes\n",
        "        blocks_repeating = v.repeat_interleave(K, dim=1)  # Left-side of the matrix    每个元素的重复次数。repeats参数会被广播来适应输入张量的维度\n",
        "        blocks_alternating = v.repeat(1, K, 1)  # Right-side of the matrix             沿着特定的维度重复这个张量，和expand()不同的是，这个函数拷贝张量的数据\n",
        "        combined = torch.cat(\n",
        "            (blocks_repeating, blocks_alternating), dim=2\n",
        "        )  # (b, K*K, 2*window_size)\n",
        "\n",
        "        if self.use_gatv2:\n",
        "            return combined.view(v.size(0), K, K, 2 * self.window_size)\n",
        "        else:\n",
        "            return combined.view(v.size(0), K, K, 2 * self.embed_dim)\n",
        "\n",
        "\n",
        "class TemporalAttentionLayer(nn.Module):\n",
        "    \"\"\"Single Graph Temporal Attention Layer\n",
        "    :param n_features: number of input features/nodes\n",
        "    :param window_size: length of the input sequence\n",
        "    :param dropout: percentage of nodes to dropout\n",
        "    :param alpha: negative slope used in the leaky rely activation function\n",
        "    :param embed_dim: embedding dimension (output dimension of linear transformation)\n",
        "    :param use_gatv2: whether to use the modified attention mechanism of GATv2 instead of standard GAT\n",
        "    :param use_bias: whether to include a bias term in the attention layer\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_features,\n",
        "        window_size,\n",
        "        dropout,\n",
        "        alpha,\n",
        "        embed_dim=None,\n",
        "        use_gatv2=True,\n",
        "        use_bias=True,\n",
        "    ):\n",
        "        super(TemporalAttentionLayer, self).__init__()\n",
        "        self.n_features = n_features\n",
        "        self.window_size = window_size\n",
        "        self.dropout = dropout\n",
        "        self.use_gatv2 = use_gatv2\n",
        "        self.embed_dim = embed_dim if embed_dim is not None else n_features\n",
        "        self.num_nodes = window_size\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "        # Because linear transformation is performed after concatenation in GATv2\n",
        "        if self.use_gatv2:\n",
        "            self.embed_dim *= 2\n",
        "            lin_input_dim = 2 * n_features\n",
        "            a_input_dim = self.embed_dim\n",
        "        else:\n",
        "            lin_input_dim = n_features\n",
        "            a_input_dim = 2 * self.embed_dim\n",
        "\n",
        "        self.lin = nn.Linear(lin_input_dim, self.embed_dim)\n",
        "        self.a = nn.Parameter(torch.zeros((a_input_dim, 1)))\n",
        "        #self.a = nn.Parameter(torch.rand((a_input_dim, 1)))\n",
        "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(window_size, window_size))\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape (b, n, k): b - batch size, n - window size, k - number of features\n",
        "        # For temporal attention a node is represented as all feature values at a specific timestamp\n",
        "\n",
        "        # 'Dynamic' GAT attention\n",
        "        # Proposed by Brody et. al., 2021 (https://arxiv.org/pdf/2105.14491.pdf)\n",
        "        # Linear transformation applied after concatenation and attention layer applied after leakyrelu\n",
        "        if self.use_gatv2:\n",
        "            a_input = self._make_attention_input(x)  # (b, n, n, 2*n_features)\n",
        "            a_input = self.leakyrelu(self.lin(a_input))  # (b, n, n, embed_dim)\n",
        "            e = torch.matmul(a_input, self.a).squeeze(3)  # (b, n, n, 1)\n",
        "\n",
        "        # Original GAT attention\n",
        "        else:\n",
        "            Wx = self.lin(x)  # (b, n, n, embed_dim)\n",
        "            a_input = self._make_attention_input(Wx)  # (b, n, n, 2*embed_dim)\n",
        "            e = self.leakyrelu(torch.matmul(a_input, self.a)).squeeze(3)  # (b, n, n, 1)\n",
        "\n",
        "        if self.use_bias:\n",
        "            e += self.bias  # (b, n, n, 1)\n",
        "\n",
        "        # Attention weights\n",
        "        attention = torch.softmax(e, dim=2)\n",
        "        attention = torch.dropout(attention, self.dropout, train=self.training)\n",
        "\n",
        "        h = self.sigmoid(torch.matmul(attention, x))  # (b, n, k)\n",
        "        return h\n",
        "\n",
        "    def _make_attention_input(self, v):\n",
        "        \"\"\"Preparing the temporal attention mechanism.\n",
        "        Creating matrix with all possible combinations of concatenations of node values:\n",
        "            (v1, v2..)_t1 || (v1, v2..)_t1\n",
        "            (v1, v2..)_t1 || (v1, v2..)_t2\n",
        "\n",
        "            ...\n",
        "            ...\n",
        "\n",
        "            (v1, v2..)_tn || (v1, v2..)_t1\n",
        "            (v1, v2..)_tn || (v1, v2..)_t2\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        K = self.num_nodes\n",
        "        blocks_repeating = v.repeat_interleave(K, dim=1)  # Left-side of the matrix\n",
        "\n",
        "        blocks_alternating = v.repeat(1, K, 1)  # Right-side of the matrix\n",
        "        combined = torch.cat((blocks_repeating, blocks_alternating), dim=2)\n",
        "\n",
        "        \n",
        "\n",
        "        if self.use_gatv2:\n",
        "            return combined.view(v.size(0), K, K, 2 * self.n_features)\n",
        "        else:\n",
        "            return combined.view(v.size(0), K, K, 2 * self.embed_dim)\n",
        "\n",
        "\n",
        "# class GRULayer(nn.Module):\n",
        "#     \"\"\"Gated Recurrent Unit (GRU) Layer\n",
        "#     :param in_dim: number of input features\n",
        "#     :param hid_dim: hidden size of the GRU\n",
        "#     :param n_layers: number of layers in GRU\n",
        "#     :param dropout: dropout rate\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, in_dim, hid_dim, n_layers, dropout):\n",
        "#         super(GRULayer, self).__init__()\n",
        "#         self.hid_dim = hid_dim\n",
        "#         self.n_layers = n_layers\n",
        "#         self.dropout = 0.0 if n_layers == 1 else dropout\n",
        "#         self.gru = nn.GRU(\n",
        "#             in_dim, hid_dim, num_layers=n_layers, batch_first=True, dropout=self.dropout\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out, h = self.gru(x)\n",
        "#         out, h = out[-1, :, :], h[-1, :, :]  # Extracting from last layer\n",
        "#         return out, h\n",
        "\n",
        "class LSTMLayer(nn.Module):\n",
        "    \"\"\"Gated Recurrent Unit (GRU) Layer\n",
        "    :param in_dim: number of input features\n",
        "    :param hid_dim: hidden size of the GRU\n",
        "    :param n_layers: number of layers in GRU\n",
        "    :param dropout: dropout rate\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_dim, hid_dim, n_layers, dropout):\n",
        "        super(LSTMLayer, self).__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = 0.0 if n_layers == 1 else dropout\n",
        "        self.lstm = nn.LSTM(\n",
        "            in_dim, hid_dim, num_layers=n_layers, batch_first=True, dropout=self.dropout\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, (h, c) = self.lstm(x)\n",
        "        out, h = out[-1, :, :], h[-1, :, :]  # Extracting from last layer\n",
        "        return out, h\n",
        "\n",
        "\n",
        "\n",
        "# class RNNDecoder(nn.Module):\n",
        "#     \"\"\"GRU-based Decoder network that converts latent vector into output\n",
        "#     :param in_dim: number of input features\n",
        "#     :param n_layers: number of layers in RNN\n",
        "#     :param hid_dim: hidden size of the RNN\n",
        "#     :param dropout: dropout rate\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, in_dim, hid_dim, n_layers, dropout):\n",
        "#         super(RNNDecoder, self).__init__()\n",
        "#         self.in_dim = in_dim\n",
        "#         self.dropout = 0.0 if n_layers == 1 else dropout\n",
        "#         self.rnn = nn.GRU(\n",
        "#             in_dim, hid_dim, n_layers, batch_first=True, dropout=self.dropout\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         decoder_out, _ = self.rnn(x)\n",
        "#         return decoder_out\n",
        "    \n",
        "class LSTMDecoder(nn.Module):\n",
        "    \"\"\"LSTM-based Decoder network that converts latent vector into output\n",
        "    :param in_dim: number of input features\n",
        "    :param n_layers: number of layers in RNN\n",
        "    :param hid_dim: hidden size of the RNN\n",
        "    :param dropout: dropout rate\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_dim, hid_dim, n_layers, dropout):\n",
        "        super(LSTMDecoder, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.dropout = 0.0 if n_layers == 1 else dropout\n",
        "        self.lstm= nn.LSTM(\n",
        "            in_dim, hid_dim, n_layers, batch_first=True, dropout=self.dropout\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        decoder_out, _ = self.lstm(x)\n",
        "        return decoder_out\n",
        "\n",
        "\n",
        "\n",
        "class ReconstructionModel(nn.Module):\n",
        "    \"\"\"Reconstruction Model\n",
        "    :param window_size: length of the input sequence\n",
        "    :param in_dim: number of input features\n",
        "    :param n_layers: number of layers in RNN\n",
        "    :param hid_dim: hidden size of the RNN\n",
        "    :param in_dim: number of output features\n",
        "    :param dropout: dropout rate\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, window_size, in_dim, hid_dim, out_dim, n_layers, dropout):\n",
        "        super(ReconstructionModel, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.decoder = LSTMDecoder(in_dim, hid_dim, n_layers, dropout)\n",
        "        self.fc = nn.Linear(hid_dim, out_dim)\n",
        "        self.sigma1 = nn.Parameter(torch.tensor(0.5))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x will be last hidden state of the GRU layer\n",
        "        h_end = x\n",
        "        h_end_rep = h_end.repeat_interleave(self.window_size, dim=1).view(\n",
        "            x.size(0), self.window_size, -1\n",
        "        )\n",
        "\n",
        "        decoder_out = self.decoder(h_end_rep)\n",
        "        out = self.fc(decoder_out)\n",
        "        out = self.sigma1 * out\n",
        "        return out\n",
        "\n",
        "\n",
        "class Forecasting_Model(nn.Module):\n",
        "    \"\"\"Forecasting model (fully-connected network)\n",
        "    :param in_dim: number of input features\n",
        "    :param hid_dim: hidden size of the FC network\n",
        "    :param out_dim: number of output features\n",
        "    :param n_layers: number of FC layers\n",
        "    :param dropout: dropout rate\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_dim, hid_dim, out_dim, n_layers, dropout):\n",
        "        super(Forecasting_Model, self).__init__()\n",
        "        layers = [nn.Linear(in_dim, hid_dim)]\n",
        "        for _ in range(n_layers - 1):\n",
        "            layers.append(nn.Linear(hid_dim, hid_dim))\n",
        "\n",
        "        layers.append(nn.Linear(hid_dim, out_dim))\n",
        "\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigma2 = nn.Parameter(torch.tensor(0.5))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            x = self.relu(self.layers[i](x))\n",
        "            x = self.dropout(x)\n",
        "            x = self.sigma2 * x\n",
        "        return self.layers[-1](x)\n"
      ],
      "metadata": {
        "id": "420yzfUkFqjF",
        "execution": {
          "iopub.status.busy": "2023-04-09T04:36:53.201972Z",
          "iopub.execute_input": "2023-04-09T04:36:53.202365Z",
          "iopub.status.idle": "2023-04-09T04:36:53.258662Z",
          "shell.execute_reply.started": "2023-04-09T04:36:53.202332Z",
          "shell.execute_reply": "2023-04-09T04:36:53.257168Z"
        },
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MTAD_GAT(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_features,\n",
        "        window_size,\n",
        "        out_dim,\n",
        "        kernel_size=7,\n",
        "        feat_gat_embed_dim=None,\n",
        "        time_gat_embed_dim=None,\n",
        "        use_gatv2=True,\n",
        "        gru_n_layers=1,\n",
        "        gru_hid_dim=150,\n",
        "        forecast_n_layers=1,\n",
        "        forecast_hid_dim=150,\n",
        "        recon_n_layers=1,\n",
        "        recon_hid_dim=150,\n",
        "        dropout=0.2,\n",
        "        alpha=0.2\n",
        "    ):\n",
        "        super(MTAD_GAT, self).__init__()\n",
        "\n",
        "        self.conv = ConvLayer(n_features, kernel_size)\n",
        "        self.feature_gat_0 = FeatureAttentionLayer0(n_features, window_size, dropout, alpha, feat_gat_embed_dim, use_gatv2= False , use_bias = False)\n",
        "        self.feature_gat_1 = FeatureAttentionLayer1(n_features, window_size, dropout, alpha, feat_gat_embed_dim, use_gatv2 , use_bias = False)\n",
        "        #self.feature_gat_2 = FeatureAttentionLayer0(n_features, window_size, dropout, alpha, feat_gat_embed_dim, use_gatv2 , use_bias = False)\n",
        "        #self.feature_gat_3 = FeatureAttentionLayer1(n_features, window_size, dropout, alpha, feat_gat_embed_dim, use_gatv2= False , use_bias = False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.temporal_gat_0 = TemporalAttentionLayer(n_features, window_size, dropout, alpha, time_gat_embed_dim, use_gatv2, use_bias = False)\n",
        "#         self.temporal_gat_1 = TemporalAttentionLayer(n_features, window_size, dropout, alpha, time_gat_embed_dim, use_gatv2, use_bias = False)\n",
        "#         self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "        self.lstm = LSTMLayer(3 * n_features, gru_hid_dim, gru_n_layers, dropout)\n",
        "        #self.gru = GRULayer(3 * n_features, gru_hid_dim, gru_n_layers, dropout)\n",
        "       \n",
        "        self.forecasting_model = Forecasting_Model(gru_hid_dim, forecast_hid_dim, out_dim, forecast_n_layers, dropout)\n",
        "        self.recon_model = ReconstructionModel(window_size, gru_hid_dim, recon_hid_dim, out_dim, recon_n_layers, dropout)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape (b, n, k): b - batch size, n - window size, k - number of features\n",
        "\n",
        "        x = self.conv(x)\n",
        "        h_feat_0 = self.feature_gat_0(x)\n",
        "        h_feat_1 = self.feature_gat_1(x)\n",
        "#         h_feat_2 = self.feature_gat_2(x)\n",
        "#         h_feat_3 = self.feature_gat_3(x)\n",
        "        h_feat = self.sigmoid(h_feat_0 + h_feat_1)\n",
        "        h_temp = self.temporal_gat_0(x)\n",
        "#         h_temp_1 = self.temporal_gat_1(x)\n",
        "#         h_temp = self.sigmoid(h_temp_1 + h_temp_0)\n",
        "        h_cat = torch.cat([x, h_feat_0, h_temp], dim=2)  # (b, n, 3k)\n",
        "        _, h_end = self.lstm(h_cat)\n",
        "        h_end = h_end.view(x.shape[0], -1)   # Hidden state for last timestamp\n",
        "\n",
        "        predictions = self.forecasting_model(h_end)\n",
        "        recons = self.recon_model(h_end)\n",
        "\n",
        "        return predictions, recons"
      ],
      "metadata": {
        "id": "PZ64Wi3uFwI4",
        "execution": {
          "iopub.status.busy": "2023-04-09T04:36:59.160581Z",
          "iopub.execute_input": "2023-04-09T04:36:59.161347Z",
          "iopub.status.idle": "2023-04-09T04:36:59.173179Z",
          "shell.execute_reply.started": "2023-04-09T04:36:59.161310Z",
          "shell.execute_reply": "2023-04-09T04:36:59.171913Z"
        },
        "trusted": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MTAD_GAT(n_features = 25,  window_size = 100, out_dim = 25, feat_gat_embed_dim = 256, time_gat_embed_dim = 64)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "YX0925OOFzkS",
        "execution": {
          "iopub.status.busy": "2023-04-09T04:37:02.459991Z",
          "iopub.execute_input": "2023-04-09T04:37:02.460700Z",
          "iopub.status.idle": "2023-04-09T04:37:02.479803Z",
          "shell.execute_reply.started": "2023-04-09T04:37:02.460662Z",
          "shell.execute_reply": "2023-04-09T04:37:02.478649Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69e1d574-6910-45a9-c76c-37da9d075dac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MTAD_GAT(\n",
              "  (conv): ConvLayer(\n",
              "    (padding): ConstantPad1d(padding=(3, 3), value=0.0)\n",
              "    (conv): Conv1d(25, 25, kernel_size=(7,), stride=(1,))\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (feature_gat_0): FeatureAttentionLayer0(\n",
              "    (lin): Linear(in_features=100, out_features=256, bias=True)\n",
              "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (feature_gat_1): FeatureAttentionLayer1(\n",
              "    (lin): Linear(in_features=200, out_features=512, bias=True)\n",
              "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (sigmoid): Sigmoid()\n",
              "  (temporal_gat_0): TemporalAttentionLayer(\n",
              "    (lin): Linear(in_features=50, out_features=128, bias=True)\n",
              "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (lstm): LSTMLayer(\n",
              "    (lstm): LSTM(75, 150, batch_first=True)\n",
              "  )\n",
              "  (forecasting_model): Forecasting_Model(\n",
              "    (layers): ModuleList(\n",
              "      (0): Linear(in_features=150, out_features=150, bias=True)\n",
              "      (1): Linear(in_features=150, out_features=25, bias=True)\n",
              "    )\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (recon_model): ReconstructionModel(\n",
              "    (decoder): LSTMDecoder(\n",
              "      (lstm): LSTM(150, 150, batch_first=True)\n",
              "    )\n",
              "    (fc): Linear(in_features=150, out_features=25, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eg_out = model(eg[0].float().to(device))\n",
        "eg_out[0].size(), eg_out[1].size()"
      ],
      "metadata": {
        "id": "gP66AqENF6A5",
        "outputId": "64a28c0b-e244-44b8-d442-0f3002c167f5",
        "execution": {
          "iopub.status.busy": "2023-04-09T04:37:04.614597Z",
          "iopub.execute_input": "2023-04-09T04:37:04.614971Z",
          "iopub.status.idle": "2023-04-09T04:37:04.681284Z",
          "shell.execute_reply.started": "2023-04-09T04:37:04.614936Z",
          "shell.execute_reply": "2023-04-09T04:37:04.680173Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 25]), torch.Size([256, 100, 25]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS =  10\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
        "forecast_criterion = nn.MSELoss()\n",
        "#weighted_criterion0 = lambda output, target: forecast_criterion(output, target) * self.alpha\n",
        "recon_criterion = nn.MSELoss()\n",
        "#weighted_criterion1 = lambda output, target: recon_criterion(output, target) * self.alpha\n",
        "len(train_dl), len(val_dl)"
      ],
      "metadata": {
        "id": "s_uLWHVUF8Dw",
        "outputId": "5850807d-5503-44b3-eda6-ea45ea44ae36",
        "execution": {
          "iopub.status.busy": "2023-04-09T04:37:06.804540Z",
          "iopub.execute_input": "2023-04-09T04:37:06.805698Z",
          "iopub.status.idle": "2023-04-09T04:37:06.815169Z",
          "shell.execute_reply.started": "2023-04-09T04:37:06.805654Z",
          "shell.execute_reply": "2023-04-09T04:37:06.814152Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(475, 53)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model_checkpoints"
      ],
      "metadata": {
        "id": "G0WwiKeZGAX7",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:50:51.224855Z",
          "iopub.execute_input": "2023-04-09T03:50:51.225323Z",
          "iopub.status.idle": "2023-04-09T03:50:52.213655Z",
          "shell.execute_reply.started": "2023-04-09T03:50:51.225287Z",
          "shell.execute_reply": "2023-04-09T03:50:52.212177Z"
        },
        "trusted": true
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Best_Valid_loss = 999999\n",
        "Best_Epoch = -1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    forecast_b_losses = []\n",
        "    recon_b_losses = []\n",
        "    \n",
        "    print(\"Epoch : \", epoch)\n",
        "    print(\"Training Started ... \")\n",
        "    \n",
        "    for batch_idx, batch in enumerate(train_dl):\n",
        "        x = batch[0].to(device).float()\n",
        "        y = batch[1].to(device).float()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        preds, recons = model(x)\n",
        "\n",
        "        forecast_loss = torch.sqrt(forecast_criterion(y.squeeze(1), preds))\n",
        "        recon_loss = torch.sqrt(recon_criterion(x, recons))\n",
        "        loss = forecast_loss + recon_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        forecast_b_losses.append(forecast_loss.item())\n",
        "        recon_b_losses.append(recon_loss.item())\n",
        "        \n",
        "\n",
        "    forecast_b_losses = np.array(forecast_b_losses)\n",
        "    recon_b_losses = np.array(recon_b_losses)\n",
        "\n",
        "    forecast_epoch_loss = np.sqrt((forecast_b_losses ** 2).mean())\n",
        "    recon_epoch_loss = np.sqrt((recon_b_losses ** 2).mean())\n",
        "\n",
        "    total_epoch_loss = forecast_epoch_loss + recon_epoch_loss\n",
        "    \n",
        "    print('Forecasting Loss : ', forecast_epoch_loss)\n",
        "    print('Reconstruction Loss : ', recon_epoch_loss)\n",
        "    \n",
        "    \n",
        "    forecast_b_losses_eval = []\n",
        "    recon_b_losses_eval = []\n",
        "    \n",
        "    print(\"Validation Started ... \")\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dl):\n",
        "            x = batch[0].to(device).float()\n",
        "            y = batch[1].to(device).float()\n",
        "\n",
        "            preds, recons = model(x)\n",
        "\n",
        "            forecast_loss = torch.sqrt(forecast_criterion(y.squeeze(1), preds))\n",
        "            recon_loss = torch.sqrt(recon_criterion(x, recons))\n",
        "            loss = forecast_loss + recon_loss\n",
        "\n",
        "            forecast_b_losses_eval.append(forecast_loss.item())\n",
        "            recon_b_losses_eval.append(recon_loss.item())\n",
        "\n",
        "    forecast_b_losses_eval = np.array(forecast_b_losses_eval)\n",
        "    recon_b_losses_eval = np.array(recon_b_losses_eval)\n",
        "\n",
        "    forecast_epoch_loss_eval = np.sqrt((forecast_b_losses_eval ** 2).mean())\n",
        "    recon_epoch_loss_eval = np.sqrt((recon_b_losses_eval ** 2).mean())\n",
        "\n",
        "    total_epoch_loss_eval = 0.5*forecast_epoch_loss_eval + 0.5*recon_epoch_loss_eval\n",
        "    \n",
        "    print('Forecasting Loss : ', forecast_epoch_loss_eval)\n",
        "    print('Reconstruction Loss : ', recon_epoch_loss_eval)\n",
        "    \n",
        "    if total_epoch_loss_eval < Best_Valid_loss:\n",
        "        Best_Valid_loss = total_epoch_loss_eval\n",
        "        Best_Epoch = epoch\n",
        "        \n",
        "        ckpt = {\n",
        "            'Epoch' : epoch,\n",
        "            'Model' : model.state_dict(),\n",
        "            'Optimizer' : optimizer.state_dict(),\n",
        "            'Train_Forecast_loss' : forecast_epoch_loss,\n",
        "            'Train_Recon_loss' : recon_epoch_loss,\n",
        "            'Eval_Forecast_loss' : forecast_epoch_loss_eval,\n",
        "            'Eval_Recon_loss' : recon_epoch_loss_eval\n",
        "        }\n",
        "        \n",
        "        torch.save(ckpt, os.path.join('model_checkpoints', str(epoch) + '.pt'))"
      ],
      "metadata": {
        "id": "PL_CjIqDGD4A",
        "outputId": "d30e4fca-31f1-4cdd-a6df-043101714e20",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:56:23.703523Z",
          "iopub.execute_input": "2023-04-09T03:56:23.704104Z",
          "iopub.status.idle": "2023-04-09T03:57:30.235778Z",
          "shell.execute_reply.started": "2023-04-09T03:56:23.704068Z",
          "shell.execute_reply": "2023-04-09T03:57:30.234706Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :  0\n",
            "Training Started ... \n",
            "Forecasting Loss :  0.10773431934925987\n",
            "Reconstruction Loss :  0.1310970797970022\n",
            "Validation Started ... \n",
            "Forecasting Loss :  0.0864743479052625\n",
            "Reconstruction Loss :  0.10197424094906253\n",
            "Epoch :  1\n",
            "Training Started ... \n",
            "Forecasting Loss :  0.0876810899182744\n",
            "Reconstruction Loss :  0.09582280989872405\n",
            "Validation Started ... \n",
            "Forecasting Loss :  0.08159810944897217\n",
            "Reconstruction Loss :  0.09186539559388296\n",
            "Epoch :  2\n",
            "Training Started ... \n",
            "Forecasting Loss :  0.08473780460725663\n",
            "Reconstruction Loss :  0.08947709128513345\n",
            "Validation Started ... \n",
            "Forecasting Loss :  0.0808050693384635\n",
            "Reconstruction Loss :  0.08877213161734335\n",
            "Epoch :  3\n",
            "Training Started ... \n",
            "Forecasting Loss :  0.08328809623990593\n",
            "Reconstruction Loss :  0.08568393347258783\n",
            "Validation Started ... \n",
            "Forecasting Loss :  0.0787444608071155\n",
            "Reconstruction Loss :  0.09047321656181047\n",
            "Epoch :  4\n",
            "Training Started ... \n",
            "Forecasting Loss :  0.08238312103758723\n",
            "Reconstruction Loss :  0.08333364458373757\n",
            "Validation Started ... \n",
            "Forecasting Loss :  0.07914218596509424\n",
            "Reconstruction Loss :  0.08311337562734056\n",
            "Epoch :  5\n",
            "Training Started ... \n",
            "Forecasting Loss :  0.08187585111998441\n",
            "Reconstruction Loss :  0.08074066329852733\n",
            "Validation Started ... \n",
            "Forecasting Loss :  0.07849826054556723\n",
            "Reconstruction Loss :  0.0789013867460383\n",
            "Epoch :  6\n",
            "Training Started ... \n",
            "Forecasting Loss :  0.08143008840210912\n",
            "Reconstruction Loss :  0.07794479857486122\n",
            "Validation Started ... \n",
            "Forecasting Loss :  0.07790606596882885\n",
            "Reconstruction Loss :  0.07871400983176495\n",
            "Epoch :  7\n",
            "Training Started ... \n",
            "Forecasting Loss :  0.0810835010151306\n",
            "Reconstruction Loss :  0.07656638594164279\n",
            "Validation Started ... \n",
            "Forecasting Loss :  0.07770872329526068\n",
            "Reconstruction Loss :  0.07858478366957751\n",
            "Epoch :  8\n",
            "Training Started ... \n",
            "Forecasting Loss :  0.08074502580711926\n",
            "Reconstruction Loss :  0.07591217074348079\n",
            "Validation Started ... \n",
            "Forecasting Loss :  0.07730541828488198\n",
            "Reconstruction Loss :  0.0728811387796122\n",
            "Epoch :  9\n",
            "Training Started ... \n",
            "Forecasting Loss :  0.08036210944703918\n",
            "Reconstruction Loss :  0.07381220752621671\n",
            "Validation Started ... \n",
            "Forecasting Loss :  0.07742006658788639\n",
            "Reconstruction Loss :  0.08164539061249716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = MTAD_GAT(n_features = 25, window_size = 100, out_dim = 25, feat_gat_embed_dim = 256, time_gat_embed_dim = 64)\n",
        "best_model.load_state_dict( torch.load( os.path.join( 'model_checkpoints', str(Best_Epoch) + '.pt' ) )['Model'] )\n",
        "best_model.to(device)"
      ],
      "metadata": {
        "id": "S1OXA9bNGODE",
        "outputId": "c5ed382a-c456-46d6-dec1-a461141d565a",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:58:18.431864Z",
          "iopub.execute_input": "2023-04-09T03:58:18.432331Z",
          "iopub.status.idle": "2023-04-09T03:58:18.471039Z",
          "shell.execute_reply.started": "2023-04-09T03:58:18.432287Z",
          "shell.execute_reply": "2023-04-09T03:58:18.469918Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MTAD_GAT(\n",
              "  (conv): ConvLayer(\n",
              "    (padding): ConstantPad1d(padding=(3, 3), value=0.0)\n",
              "    (conv): Conv1d(25, 25, kernel_size=(7,), stride=(1,))\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (feature_gat_0): FeatureAttentionLayer0(\n",
              "    (lin): Linear(in_features=100, out_features=256, bias=True)\n",
              "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (feature_gat_1): FeatureAttentionLayer1(\n",
              "    (lin): Linear(in_features=200, out_features=512, bias=True)\n",
              "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (sigmoid): Sigmoid()\n",
              "  (temporal_gat_0): TemporalAttentionLayer(\n",
              "    (lin): Linear(in_features=50, out_features=128, bias=True)\n",
              "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              "  (lstm): LSTMLayer(\n",
              "    (lstm): LSTM(75, 150, batch_first=True)\n",
              "  )\n",
              "  (forecasting_model): Forecasting_Model(\n",
              "    (layers): ModuleList(\n",
              "      (0): Linear(in_features=150, out_features=150, bias=True)\n",
              "      (1): Linear(in_features=150, out_features=25, bias=True)\n",
              "    )\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (recon_model): ReconstructionModel(\n",
              "    (decoder): LSTMDecoder(\n",
              "      (lstm): LSTM(150, 150, batch_first=True)\n",
              "    )\n",
              "    (fc): Linear(in_features=150, out_features=25, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smap_data_test = []\n",
        "for smap_channel in smap_channels:\n",
        "    tmp_data = np.load(os.path.join('data/test/', smap_channel + '.npy'))\n",
        "    smap_data_test.extend(tmp_data)\n",
        "    \n",
        "smap_data_test = np.array(smap_data_test)\n",
        "print(\"Shape of Test DataSet : \", smap_data_test.shape)"
      ],
      "metadata": {
        "id": "OsZLixSJGSJC",
        "outputId": "639eaec2-5b77-4e3b-9872-9392237d7360",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:41:39.005598Z",
          "iopub.execute_input": "2023-04-09T03:41:39.005953Z",
          "iopub.status.idle": "2023-04-09T03:41:39.303266Z",
          "shell.execute_reply.started": "2023-04-09T03:41:39.005921Z",
          "shell.execute_reply": "2023-04-09T03:41:39.302121Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Test DataSet :  (427617, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smap_data_test_norm, _ = normalize_data(smap_data_test, scaler)\n",
        "smap_data_test_norm = smap_data_test_norm[:10000]\n",
        "smap_data_test_pt = torch.from_numpy(smap_data_test_norm)\n",
        "smap_data_test_pt.size()"
      ],
      "metadata": {
        "id": "D35iN0JXGULL",
        "outputId": "457d781d-5b91-4c8a-dc88-694b7c03d532",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:41:41.960935Z",
          "iopub.execute_input": "2023-04-09T03:41:41.961667Z",
          "iopub.status.idle": "2023-04-09T03:41:42.712964Z",
          "shell.execute_reply.started": "2023-04-09T03:41:41.961624Z",
          "shell.execute_reply": "2023-04-09T03:41:42.711941Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data normalized\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smap_test_x_y = SlidingWindowDataset(smap_data_test_pt, 100)\n",
        "test_dl = torch.utils.data.DataLoader(smap_test_x_y, batch_size=256, shuffle=False)\n",
        "print(\"Number of Batches in Test Dataloader : \", len(test_dl))"
      ],
      "metadata": {
        "id": "vhUi8PaxGW3j",
        "outputId": "d1e32a0e-61f3-4b2b-85d3-5aed07363799",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:41:45.091494Z",
          "iopub.execute_input": "2023-04-09T03:41:45.092062Z",
          "iopub.status.idle": "2023-04-09T03:41:45.098345Z",
          "shell.execute_reply.started": "2023-04-09T03:41:45.092026Z",
          "shell.execute_reply": "2023-04-09T03:41:45.097342Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Batches in Test Dataloader :  39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "preds = []\n",
        "recons = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dl):\n",
        "        x = batch[0].to(device).float()\n",
        "        y = batch[1].to(device).float()\n",
        "\n",
        "        y_hat, _ = model(x)\n",
        "\n",
        "        # Shifting input to include the observed value (y) when doing the reconstruction\n",
        "        recon_x = torch.cat((x[:, 1:, :], y), dim=1)\n",
        "        _, window_recon = model(recon_x)\n",
        "\n",
        "        preds.append(y_hat.detach().cpu().numpy())\n",
        "        # Extract last reconstruction only\n",
        "        recons.append(window_recon[:, -1, :].detach().cpu().numpy())\n",
        "\n",
        "    preds = np.concatenate(preds, axis=0)\n",
        "    recons = np.concatenate(recons, axis=0)"
      ],
      "metadata": {
        "id": "7kzhYPuvGZ51",
        "outputId": "fba95950-0b29-4469-a4de-176d3d766b16",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:41:47.140918Z",
          "iopub.execute_input": "2023-04-09T03:41:47.141615Z",
          "iopub.status.idle": "2023-04-09T03:41:51.745268Z",
          "shell.execute_reply.started": "2023-04-09T03:41:47.141577Z",
          "shell.execute_reply": "2023-04-09T03:41:51.744181Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "96e7b3c4847048b3886e97eb0c3529af",
            "48b29049446e4838b731ec1c6f74ed0a",
            "f3fd28b2daf0498098e9b1e09f2f1875",
            "ea9faea6b7274c30a733e2e57b19319f",
            "a525147ac1b04af8be036b41a2d5f2cc",
            "d0a03ccf9fcc4d7fa40eea0f20c22289",
            "e66f4d780b064b57942a4c7bd70e0840",
            "7dcbdfe3ce27437fa22578957b12d1a4",
            "8ea3c5665fb34374b71c60836a1f3763",
            "dfba0ae200d149258e39ea392c3288dc",
            "f1bb6cb8a28842c69b104d01f99e9e6b"
          ]
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/39 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96e7b3c4847048b3886e97eb0c3529af"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.shape, recons.shape\n",
        "scale_scores = True"
      ],
      "metadata": {
        "id": "Qdyb2SzuGhX8",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:41:55.388637Z",
          "iopub.execute_input": "2023-04-09T03:41:55.389212Z",
          "iopub.status.idle": "2023-04-09T03:41:55.397156Z",
          "shell.execute_reply.started": "2023-04-09T03:41:55.389139Z",
          "shell.execute_reply": "2023-04-09T03:41:55.395964Z"
        },
        "trusted": true
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual = smap_data_test_norm[Window:]\n",
        "print(actual.shape)\n",
        "\n",
        "anomaly_scores = np.zeros_like(actual)\n",
        "df = pd.DataFrame()\n",
        "for i in range(preds.shape[1]):\n",
        "    df[f\"Forecast_{i}\"] = preds[:, i]\n",
        "    df[f\"Recon_{i}\"] = recons[:, i]\n",
        "    df[f\"True_{i}\"] = actual[:, i]\n",
        "    a_score = np.sqrt((preds[:, i] - actual[:, i]) ** 2) + np.sqrt(\n",
        "        (recons[:, i] - actual[:, i]) ** 2)\n",
        "\n",
        "    if scale_scores:\n",
        "        q75, q25 = np.percentile(a_score, [75, 25])\n",
        "        iqr = q75 - q25\n",
        "        median = np.median(a_score)\n",
        "        a_score = (a_score - median) / (1+iqr)\n",
        "\n",
        "    anomaly_scores[:, i] = a_score\n",
        "    df[f\"A_Score_{i}\"] = a_score\n",
        "\n",
        "anomaly_scores = np.mean(anomaly_scores, 1)\n",
        "df['A_Score_Global'] = anomaly_scores"
      ],
      "metadata": {
        "id": "esXBxwVGGkEo",
        "outputId": "197328f2-e248-4bdd-e0ac-f472b9d59690",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:41:57.378915Z",
          "iopub.execute_input": "2023-04-09T03:41:57.379607Z",
          "iopub.status.idle": "2023-04-09T03:41:57.478026Z",
          "shell.execute_reply.started": "2023-04-09T03:41:57.379553Z",
          "shell.execute_reply": "2023-04-09T03:41:57.475740Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9900, 25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-bbbe538e9e64>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['A_Score_Global'] = anomaly_scores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_data = df.to_csv('score_1.csv', index = True)\n",
        "df"
      ],
      "metadata": {
        "id": "tTV8rElqGloB",
        "outputId": "2f8ddb5e-f525-4498-90d1-7e3e0ba25335",
        "execution": {
          "iopub.status.busy": "2023-04-09T03:42:07.928818Z",
          "iopub.execute_input": "2023-04-09T03:42:07.929508Z",
          "iopub.status.idle": "2023-04-09T03:42:08.957535Z",
          "shell.execute_reply.started": "2023-04-09T03:42:07.929473Z",
          "shell.execute_reply": "2023-04-09T03:42:08.956170Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Forecast_0   Recon_0    True_0  A_Score_0  Forecast_1   Recon_1  True_1  \\\n",
              "0       0.952727  0.960019  1.000000  -0.005868    0.009776 -0.001783     0.0   \n",
              "1       0.955124  0.960135  1.000000  -0.008282    0.009993 -0.001620     0.0   \n",
              "2       0.954229  0.960200  1.000000  -0.007484    0.010110 -0.001354     0.0   \n",
              "3       0.956674  0.959991  1.000000  -0.009632    0.010367 -0.001207     0.0   \n",
              "4       0.955022  0.958941  1.000000  -0.007037    0.010401 -0.001279     0.0   \n",
              "...          ...       ...       ...        ...         ...       ...     ...   \n",
              "9895    0.337292 -0.115536  0.144039   0.345199    0.001096  0.155344     0.0   \n",
              "9896    0.197003 -0.003861  0.144039   0.103234   -0.000650  0.053595     0.0   \n",
              "9897    0.113234  0.132231  0.144039  -0.048738   -0.002300  0.037999     0.0   \n",
              "9898    0.131095  0.202282  0.139819  -0.021297   -0.001897  0.030896     0.0   \n",
              "9899    0.169557  0.250145  0.139819   0.044846    0.001401  0.025400     0.0   \n",
              "\n",
              "      A_Score_1  Forecast_2   Recon_2  ...  A_Score_22   Forecast_23  \\\n",
              "0     -0.004031    0.000511  0.000926  ...   -0.001784 -1.989262e-06   \n",
              "1     -0.003978    0.000567  0.000857  ...   -0.001976 -1.963720e-06   \n",
              "2     -0.004122    0.000579  0.000747  ...   -0.002296 -1.926468e-06   \n",
              "3     -0.004016    0.000600  0.000590  ...   -0.002576 -1.874917e-06   \n",
              "4     -0.003913    0.000585  0.000389  ...   -0.002968 -1.834807e-06   \n",
              "...         ...         ...       ...  ...         ...           ...   \n",
              "9895   0.136169   -0.000838  0.001816  ...    0.006198 -8.049562e-07   \n",
              "9896   0.037277   -0.002960 -0.000270  ...   -0.002206 -7.075462e-07   \n",
              "9897   0.023781   -0.003321 -0.001472  ...   -0.000044 -9.843636e-07   \n",
              "9898   0.016518   -0.003227 -0.002546  ...    0.001757 -1.160013e-06   \n",
              "9899   0.010720   -0.002882 -0.002842  ...    0.004410 -3.722557e-07   \n",
              "\n",
              "      Recon_23  True_23  A_Score_23   Forecast_24  Recon_24  True_24  \\\n",
              "0     0.001098      0.0    0.000211 -3.414730e-10  0.001461      0.0   \n",
              "1     0.001097      0.0    0.000211 -2.448125e-10  0.001468      0.0   \n",
              "2     0.001097      0.0    0.000210 -2.094999e-10  0.001475      0.0   \n",
              "3     0.001094      0.0    0.000208 -1.695092e-10  0.001476      0.0   \n",
              "4     0.001088      0.0    0.000201 -1.644644e-10  0.001459      0.0   \n",
              "...        ...      ...         ...           ...       ...      ...   \n",
              "9895 -0.000356      0.0   -0.000531  3.468313e-09  0.000413      0.0   \n",
              "9896 -0.000334      0.0   -0.000553  1.343798e-09  0.000454      0.0   \n",
              "9897 -0.000272      0.0   -0.000615  3.906150e-10  0.000499      0.0   \n",
              "9898 -0.000227      0.0   -0.000659 -4.501588e-11  0.000511      0.0   \n",
              "9899 -0.000197      0.0   -0.000691 -5.115958e-10  0.000505      0.0   \n",
              "\n",
              "      A_Score_24  A_Score_Global  \n",
              "0       0.000163       -0.001321  \n",
              "1       0.000170       -0.001421  \n",
              "2       0.000177       -0.001467  \n",
              "3       0.000178       -0.001587  \n",
              "4       0.000160       -0.001587  \n",
              "...          ...             ...  \n",
              "9895   -0.000884        0.031157  \n",
              "9896   -0.000843        0.006769  \n",
              "9897   -0.000799       -0.002129  \n",
              "9898   -0.000787       -0.001046  \n",
              "9899   -0.000792        0.001845  \n",
              "\n",
              "[9900 rows x 101 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8385c2b-df87-4d39-a2c5-7789285ef55f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Forecast_0</th>\n",
              "      <th>Recon_0</th>\n",
              "      <th>True_0</th>\n",
              "      <th>A_Score_0</th>\n",
              "      <th>Forecast_1</th>\n",
              "      <th>Recon_1</th>\n",
              "      <th>True_1</th>\n",
              "      <th>A_Score_1</th>\n",
              "      <th>Forecast_2</th>\n",
              "      <th>Recon_2</th>\n",
              "      <th>...</th>\n",
              "      <th>A_Score_22</th>\n",
              "      <th>Forecast_23</th>\n",
              "      <th>Recon_23</th>\n",
              "      <th>True_23</th>\n",
              "      <th>A_Score_23</th>\n",
              "      <th>Forecast_24</th>\n",
              "      <th>Recon_24</th>\n",
              "      <th>True_24</th>\n",
              "      <th>A_Score_24</th>\n",
              "      <th>A_Score_Global</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.952727</td>\n",
              "      <td>0.960019</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.005868</td>\n",
              "      <td>0.009776</td>\n",
              "      <td>-0.001783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.004031</td>\n",
              "      <td>0.000511</td>\n",
              "      <td>0.000926</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001784</td>\n",
              "      <td>-1.989262e-06</td>\n",
              "      <td>0.001098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000211</td>\n",
              "      <td>-3.414730e-10</td>\n",
              "      <td>0.001461</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>-0.001321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.955124</td>\n",
              "      <td>0.960135</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.008282</td>\n",
              "      <td>0.009993</td>\n",
              "      <td>-0.001620</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.003978</td>\n",
              "      <td>0.000567</td>\n",
              "      <td>0.000857</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001976</td>\n",
              "      <td>-1.963720e-06</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000211</td>\n",
              "      <td>-2.448125e-10</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000170</td>\n",
              "      <td>-0.001421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.954229</td>\n",
              "      <td>0.960200</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.007484</td>\n",
              "      <td>0.010110</td>\n",
              "      <td>-0.001354</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.004122</td>\n",
              "      <td>0.000579</td>\n",
              "      <td>0.000747</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002296</td>\n",
              "      <td>-1.926468e-06</td>\n",
              "      <td>0.001097</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000210</td>\n",
              "      <td>-2.094999e-10</td>\n",
              "      <td>0.001475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>-0.001467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.956674</td>\n",
              "      <td>0.959991</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.009632</td>\n",
              "      <td>0.010367</td>\n",
              "      <td>-0.001207</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.004016</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002576</td>\n",
              "      <td>-1.874917e-06</td>\n",
              "      <td>0.001094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000208</td>\n",
              "      <td>-1.695092e-10</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>-0.001587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.955022</td>\n",
              "      <td>0.958941</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.007037</td>\n",
              "      <td>0.010401</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.003913</td>\n",
              "      <td>0.000585</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002968</td>\n",
              "      <td>-1.834807e-06</td>\n",
              "      <td>0.001088</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000201</td>\n",
              "      <td>-1.644644e-10</td>\n",
              "      <td>0.001459</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>-0.001587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9895</th>\n",
              "      <td>0.337292</td>\n",
              "      <td>-0.115536</td>\n",
              "      <td>0.144039</td>\n",
              "      <td>0.345199</td>\n",
              "      <td>0.001096</td>\n",
              "      <td>0.155344</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.136169</td>\n",
              "      <td>-0.000838</td>\n",
              "      <td>0.001816</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006198</td>\n",
              "      <td>-8.049562e-07</td>\n",
              "      <td>-0.000356</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000531</td>\n",
              "      <td>3.468313e-09</td>\n",
              "      <td>0.000413</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000884</td>\n",
              "      <td>0.031157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9896</th>\n",
              "      <td>0.197003</td>\n",
              "      <td>-0.003861</td>\n",
              "      <td>0.144039</td>\n",
              "      <td>0.103234</td>\n",
              "      <td>-0.000650</td>\n",
              "      <td>0.053595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037277</td>\n",
              "      <td>-0.002960</td>\n",
              "      <td>-0.000270</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002206</td>\n",
              "      <td>-7.075462e-07</td>\n",
              "      <td>-0.000334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000553</td>\n",
              "      <td>1.343798e-09</td>\n",
              "      <td>0.000454</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000843</td>\n",
              "      <td>0.006769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9897</th>\n",
              "      <td>0.113234</td>\n",
              "      <td>0.132231</td>\n",
              "      <td>0.144039</td>\n",
              "      <td>-0.048738</td>\n",
              "      <td>-0.002300</td>\n",
              "      <td>0.037999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023781</td>\n",
              "      <td>-0.003321</td>\n",
              "      <td>-0.001472</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000044</td>\n",
              "      <td>-9.843636e-07</td>\n",
              "      <td>-0.000272</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000615</td>\n",
              "      <td>3.906150e-10</td>\n",
              "      <td>0.000499</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000799</td>\n",
              "      <td>-0.002129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9898</th>\n",
              "      <td>0.131095</td>\n",
              "      <td>0.202282</td>\n",
              "      <td>0.139819</td>\n",
              "      <td>-0.021297</td>\n",
              "      <td>-0.001897</td>\n",
              "      <td>0.030896</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016518</td>\n",
              "      <td>-0.003227</td>\n",
              "      <td>-0.002546</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001757</td>\n",
              "      <td>-1.160013e-06</td>\n",
              "      <td>-0.000227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000659</td>\n",
              "      <td>-4.501588e-11</td>\n",
              "      <td>0.000511</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000787</td>\n",
              "      <td>-0.001046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9899</th>\n",
              "      <td>0.169557</td>\n",
              "      <td>0.250145</td>\n",
              "      <td>0.139819</td>\n",
              "      <td>0.044846</td>\n",
              "      <td>0.001401</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010720</td>\n",
              "      <td>-0.002882</td>\n",
              "      <td>-0.002842</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004410</td>\n",
              "      <td>-3.722557e-07</td>\n",
              "      <td>-0.000197</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000691</td>\n",
              "      <td>-5.115958e-10</td>\n",
              "      <td>0.000505</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.000792</td>\n",
              "      <td>0.001845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9900 rows × 101 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8385c2b-df87-4d39-a2c5-7789285ef55f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8385c2b-df87-4d39-a2c5-7789285ef55f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8385c2b-df87-4d39-a2c5-7789285ef55f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}